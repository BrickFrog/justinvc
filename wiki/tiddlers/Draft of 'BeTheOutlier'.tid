author: ShrilataMurthy
caption: Be the Outlier: How to Ace Data Science Interviews
completed: 
created: 20220417223518157
draft.of: BeTheOutlier
draft.title: BeTheOutlier
medium: book
modified: 20220419025907492
rating: 
readstatus: partial
tags: Source Interviewing Public
title: Draft of 'BeTheOutlier'
type: text/vnd.tiddlywiki
url: 
year: 2020

A DataScience interview book. I've found myself needing to go over the basics and making [[Anki]] cards out of them (see [[BeTheOutlier/Questions]]). This one is relatively short so I figured I'd do this one first. It's about ~150 pages, so shouldn't be too bad.

!! Technical Rounds
* Modeling and Machine Learning

!!! [[Overfitting]] in Predictive Models

* BiasVarianceTradeoff
** Reduction of model complexity - too many features (forward stepwise)
** Regularization - shrink/regularize coefficient estimates towards zero
*** Ridge
**** Loss function / residual sum of squares is minimized by shrinkage quantity, making use of lambda as a tuning parameter - increasing leading coefficient towards zero
*** Lasso
**** Penalizing high value coefficient, shrinking them to zero as opposed to shrinking like in ridge.
*** Cross-validation as a preventative measure, K-Fold

!!! K-Means Clustering Clusters

* Commonly used process is the Elbow Curve - reducing intra-cluster variation, minimizing the WSS (within-cluster sum of square) - when plotted you can tell the huge drop off after X clusters. (typically Euclidian distance)

!!! Favorite Algorithm

* More of a general question, but it is suggested to follow the path:
** My favorite algorithm is...
** This can be used for...
** It works this way...
** It's good in general because...
** I used it to...

Some miscellaneous questions on random forests and topics to investigate:

* InformationGain, GiniIndex, [[Bagging]], [[Boosting]], GradientBoosting, [[XGBoost]], RandomForest

!!! Evaluating Performance

* Classification
** ConfusionMatrix
*** TARGET VS ACTUALS
*** Positive / Positive (True Positive)
*** Positive / Negative (False Positive - Type I Error)
*** Negative / Positive (False Negative - Type II Error)
*** Negative / Negative (True Negative)
*** Precision - TP / (TP + FP)
*** Negative Predicted Value - TN / (TN +FN)
*** Sensitivity / Recall - TP / (TP + FN)
*** Specificity - TN / (TN + FP)
*** Overall Accuracy - (TP + TN) / (TP + TN + FP + FN)
** F1 Score
*** Balancing betwen precision and recall, harmonic mean of precision and recall, punishing extreme values to keep balance
** AUC (Area Under ROC)
*** Shows tradeoff between specitivity and sensitivity, showing them on the x and y axis respectively
* Regression
** RMSE
*** $$
R M S E=\sqrt{\frac{\sum_{i=1}^{N}\left(\text { Predicted }_{i}-\text { Actual }_{i}\right)^{2}}{N}}
$$
*** Measure of how spread out residuals are, difference between actuals and predicted, penalizing higher prediction errors more than MAE
** MAE
** $$
M A E=\frac{1}{n} \sum_{j=1}^{n}\left|y_{j}-\hat{y}_{0 j}\right|
$$
*** Average of the absolute difference between the preidcted values and observed value
** R-Square
*** $$
\begin{aligned}
R^{2} &=1-\frac{\sum_{i=1}^{n}\left(Y_{i}-\widehat{Y_{l}}\right)^{2}}{\sum_{i=1}^{n}\left(Y_{i}-\bar{Y}\right)^{2}} \\
R_{a d j}^{2} &=1-\left[\frac{\left(1-R^{2}\right)(n-1)}{n-k-1}\right]
\end{aligned}
$$
*** Adjusted R-Square penalizes features, and will always be less or equal to R-Square
** Additionally, check if the model is directionally correct, whether the sign of the coefficients is directionally intuitive

!!! ARIMA Parameters

* Trend / Seasonality / Cyclicity / Randomness (Noise)
* Three key parameters
** P (periods for lag)
** D (differencing - stationary)
** Q (lag of error component)
** P & Q, ACF and PACF plots
*** ACF - auto-correlation plot between predictor variable and its lagged values
*** PACF, partial-auto-correlation plot at lag Q is the correlation that results after removing the effect of any correlations due to the terms at shorter lag.
*** Looking at tailing off as the effect weakens
** D
*** Stationarity, plots of differenced variables can be inspected to determine when it does not have trend/seasonality


!!! Probability